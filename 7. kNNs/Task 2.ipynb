{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abuebayyeh/imperial_eee_machine_learning_course/blob/main/07_ML_kNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b6fcf2",
      "metadata": {
        "id": "30b6fcf2"
      },
      "source": [
        "# k-nearest neighbour (k-NN)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The k-Nearest Neighbors (k-NN) algorithm is a versatile supervised machine learning technique suitable for both classification and regression tasks. At its core, k-NN operates on the principle that you can determine the label or value of a data point by examining its proximity to other data points with known labels or values. In essence, it's like asking your neighbors for advice when you're unsure about something – your decision is influenced by what your nearby neighbors think.\n",
        "\n",
        "## Understanding the Basics\n",
        "\n",
        "Here's a breakdown of the fundamental concepts behind the k-NN algorithm:\n",
        "\n",
        "### 1. Nearest Neighbors\n",
        "\n",
        "When using k-NN, the algorithm identifies the k data points that are closest to the data point you want to classify or predict. These data points serve as your \"neighbors\" in the feature space. The choice of distance metric, such as Euclidean or Manhattan distance, determines how we measure this closeness.\n",
        "\n",
        "### 2. Selecting 'k'\n",
        "\n",
        "One crucial parameter you must decide on is 'k,' the number of nearest neighbors to consider. The value of 'k' significantly influences the algorithm's behavior. To illustrate, let's say we have two classes, represented as △ and □, and we want to classify an unknown point represented by a question mark (?).\n",
        "\n",
        "   - If 'k' is set to 1, the algorithm assigns the class of the closest neighbor, in this case, △.\n",
        "   - If 'k' is set to 3, the algorithm looks at the three nearest neighbors and assigns the class based on the majority, which in this example would be □.\n",
        "\n",
        "![knn.gif](data:image/gif;base64,R0lGODlhmgFxAXD+ACH+NSBJbWFnZSBnZW5lcmF0ZWQgYnkgR1BMIEdob3N0c2NyaXB0IChkZXZpY2U9cHBtcmF3KQoAACH5BAAAAAAALAAAAACaAXEBhwAAAAAAMwAAZgAAmQAAzAAA/wArAAArMwArZgArmQArzAAr/wBVAABVMwBVZgBVmQBVzABV/wCAAACAMwCAZgCAmQCAzACA/wCqAACqMwCqZgCqmQCqzACq/wDVAADVMwDVZgDVmQDVzADV/wD/AAD/MwD/ZgD/mQD/zAD//zMAADMAMzMAZjMAmTMAzDMA/zMrADMrMzMrZjMrmTMrzDMr/zNVADNVMzNVZjNVmTNVzDNV/zOAADOAMzOAZjOAmTOAzDOA/zOqADOqMzOqZjOqmTOqzDOq/zPVADPVMzPVZjPVmTPVzDPV/zP/ADP/MzP/ZjP/mTP/zDP//2YAAGYAM2YAZmYAmWYAzGYA/2YrAGYrM2YrZmYrmWYrzGYr/2ZVAGZVM2ZVZmZVmWZVzGZV/2aAAGaAM2aAZmaAmWaAzGaA/2aqAGaqM2aqZmaqmWaqzGaq/2bVAGbVM2bVZmbVmWbVzGbV/2b/AGb/M2b/Zmb/mWb/zGb//5kAAJkAM5kAZpkAmZkAzJkA/5krAJkrM5krZpkrmZkrzJkr/5lVAJlVM5lVZplVmZlVzJlV/5mAAJmAM5mAZpmAmZmAzJmA/5mqAJmqM5mqZpmqmZmqzJmq/5nVAJnVM5nVZpnVmZnVzJnV/5n/AJn/M5n/Zpn/mZn/zJn//8wAAMwAM8wAZswAmcwAzMwA/8wrAMwrM8wrZswrmcwrzMwr/8xVAMxVM8xVZsxVmcxVzMxV/8yAAMyAM8yAZsyAmcyAzMyA/8yqAMyqM8yqZsyqmcyqzMyq/8zVAMzVM8zVZszVmczVzMzV/8z/AMz/M8z/Zsz/mcz/zMz///8AAP8AM/8AZv8Amf8AzP8A//8rAP8rM/8rZv8rmf8rzP8r//9VAP9VM/9VZv9Vmf9VzP9V//+AAP+AM/+AZv+Amf+AzP+A//+qAP+qM/+qZv+qmf+qzP+q///VAP/VM//VZv/Vmf/VzP/V////AP//M///Zv//mf//zP///wAAAAAAAAAAAAAAAAj/APcJHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKHEmypMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq5Yhmq9evYE0qAzAsrNmzaCuKARAjrdu3cAmOBQAgWty7eL/GoAtARd6/gKkqywQgDbHAiBMzrQcgk+LHkImOLRu5smWdyxpf3sy5pJgbAjUbHKups+nTHQGEVnZQn2jUsGNLBMC67cHJsnPrXigmUybWBzM73k28+L5hMcQkpAegtPHnuVUnHDscunXTOA4nzEz5uvfKbKsjEmQu/rt5xGK6T29+vj1qxuXdy/+PjHv+RWX48wPXXw9aPftMCQcgQ8NMggYaYogRBnCMoDGJJGlIMolAxEAoiRgIaieJg5kQg9+AQJEG4j7EZGIghhPuk19/GC2DX4kmCjRMGpkMA9yINZEnnzIlAidJh8rQo1I0JRpo4H44wlSfd4Nh2Jt2Nv0nEIpQJpmSgM8tM8xwPN7oEz2DHRiflSKJSJwyG/bm5VFSckimSDrulokkzkFVT5OT/PZmR0uelgkakmw12CT67LkRlp1lkmAmy5ylqJ6GUmQmZ2hAmtagvUUqUZyV/YnYJGFoClGfic0pRpWJ5SnqQogiNsyTluG55qoCTfoXkqahiQaqq3KKV4l+yslWIq1ykZWXMhjOKlumq7bqFj0OKqubgWNaaatbLn5Hz5GR+moWNKrKJ4a0IJIK1iSnlkvufM569SiOyKYIL3thhWvlq9W65y2xV6G77nfmWqXovyPyCGK7gkXIr0DQ8GretVQNvPBAGM63r1QSTlwQMcyeF3BUBK+qzxj5/xqHsFNiNBrgh/v4luckBgpUj29AhizUnB7TyxM0++gTTaE8+wx0zz/bJSMa6gHl4n4OotHgJJSVOIwmw4BCWTQ1amLijwKZ6JuHSvF83cU2ZdJGG2ecfXbaarN9thkCRWj0TyUCiqEkUtrs0It/jrtPw3rTxLGU0H1c0ydnu9GG4owv7njjyCaNk4s1dq0JMWJfOSeHDueEbMmxnVxTMomXrrjjj5/d4U4NXxhtTXVz6VOlheusE+JuXJJ7G5jw3obul/h+tue15hn4S5PckCfhOKH7HNmHl4566qcrfpOJ6RZVN+052Wic4TSZHXzuivcufO+7C47gJMfrZDCJmf9rPJHoNJGeeht0OD5H42fP/RK47QPKnNIwDP/tIxn4QaAyFMjABCbQIw/aDcRugrtLzOF8iwve707nEh7t6ir1IAaHhCQQtZnwhCgcgkei4SDdQK9+amsc/9yQv9MVSiVoImAAkUIPrQ2ketID4vRAIsId3spYPKng7no3B939LoPWU0kasuco1AnxisMjIhqYZxr6zQR3ibsg45x4ujao8CS4Sssy0Oc78kGxjVkkIujoY7ucIM6JGHyj+Uxios6d5WxMPB0dxifGDbaBVi+cif3gKMjFFfKQI1FGhIxYFTyeznzVw+MZR2IpzoBvJmZT3P6CN0jFjW98kASJoiT/QUmrjJGRwHtc8EpSjxu0Uo2v0Qnpyme6Xp4ufh0BW2CY6Lj86a6QnSjjSTp2mQnaBHGlM1/vpHm2WfJpEsAEzBsN+Ub+oYSZlUmkTMAYyCDub3E94BM4A5PJxrExcRpMCRUr80mZeOKEZZSeCTeCrK5EBnX5cyQg54DJOJ4km4/xokyUcYZkfOKhnnCoQz+RjIhS9BOY0IjEKrNEQMLRcWxkyS2/4syazPMkfkQM9WJoyX2uhH3hzCVO0pOSOSKmd53I4CjdIEYLujENK0HWSLVSz5f4BiVoktdmVtpOK7bhVUOFCD38llCZRgmpJDvNK3fnRtTtcTBBDZZiSqokUaQ+CKGWKd0gBZq7UpZOLlHdm1gRI06WvAolR4WN+VDI17OxQS5UPYlN3VJUlXhKftBIBjTys1hlLFaxjo1sMgyyzgEpFIeSUBlJ7JUk56FkWP+BIStLUmaSCO5JUWgFyYICU1eUIM0klU0SMTRbEmTR9i6FPUmdyhTYouRNP/jJW1NIWBIRAuayKIsrSk2EoIqpaAwSQkMjXruPEyWIs0OJ7UdidKw6tgSsJrnhTng0J+18jTX64OJ4/kZeCgFqEsKc3W5Hgs28tJYkJ92ucj/SzyftdyBE6ttgYyKGQM0ntyLB7naVShMPCgRMKpFSPTj0341wt7jifQtyRWLckQyuJvoghpEGPJKGZYIRmdAEcWuiYFUy+FLeTQk0xJDh7fqTJppQk+darBU0VPgo91VlSjPCsZmAt8Y8eV1NCkiSepD2LQgeCrgWii4S02RmYoD/6UxaSBKcadiqwgLUkH2ijAzNJGObtbJgYgzbH5NIckH9IFNYJhPuiWTKzwJzSS7MXzEYsKZuXqh2UYJiJiExJWXmbaAVUqE0rBhk/npJNOYaEjqbZcNcGbNFWNmSjWIFQ4+GCqXBItoFi2TQIlEUnK1CDKC+RBm39cgwbhyWIGtk1BwBr0X04dj+KIPX0aDHYvWxDGgI+0bx9coNF52QCuFX02tetUiQXBNlDMGE+cz22WiNliy3xM4hwbVWMD3ekSrjozN0akbh8idoQ1DNEeGzV0rNEXHf2t0KgQY8O9o74JmyDcweSuTCGkl4D1fPpgYJATVCjxj20qmKmyxerg6LaB+f6dD4DcmJN6JvrmrQjVw9W8C1J9LagoXcFcmrR5DFkWX48p5hhKPEb/VipLCcpGzuSD1CBZLeYkQf8LSiv88W0NS+JWYp0TJIoPYVW1MkxSHBd0PObT5jihKITvxEqdAQat6OBAc4l3augaJvx+GRmvwbeVI49udU13wjdPIKysPHX1+mbq3mmzlikNX1cLvZ3lOht0UszREeXwToHieoR52qdqU0PtEaN/84kBGuETkHk9uHcjhAS4dHvT9m5Ib/uXqrEuWI3NwjPud4BttwTzdWffVG/wuq3zT3hyidIyr3SMMfDsSCar0yy5CE1HNye9LnHCOnzzXgMdJxDDoxmasHeDPFEHsLD9/2kieK0x8i/I/cqUzcZNw50+15pJKQajRL9k6myuwZnzorpX9IGqi9M9TB3ImnrKH0xVKkpjVKH3niMnmlKHliI40nV6WVfQuRe1RRe99FEsOAQmWUT2rze5U2HJrwI8RAfwgxKFOURlkBGiCRfGs2Xzshbx8RDZhwUSxIUZ7Agg7lCRw4eIqSZdfHEItygNNRXG+XEZZHFdvHEKuDeh7/NhOTgGKBRg/MpX4r4WUjQV0rJ3ZNEX8MgXkZwTWVtnwkAVrVxyed1BILF0ltBxkOuB0G1hFaeBHU913UAhMTdoO3poN0ZIIYYXEdwYBoKIUalyxGdiFweB9piBF/uBAiCISURxGBGBE9mBF4aBI9chNhooBPt4iVN4gJAV/Gp4fxRok2UWSIJhAzGBPKwAgsIYkMgSYjaIo8UYYH4T1AwWspwTGW+IlOkQYVlnpOIXguMYRJoQyT4AZDwS14FUlneIeqqBNB+E1dOBHvYxLJkF8/MVXH2BAwMxK4mBGJWBRUiBDZ6BAzMoJoEGsaNwahuIowU44bYYdCBhKaeBSs7ygXnCgRjuZiKIGOPmEg4vgRnjgvdEgR6qgRszaCxchh/ZgYnDYUY7gUyUhZHmEYIPGDWSiHJBFiJbEM3SgR00gQ3QcyGGcRBSJrCWkR+5hqNCYVs8eI1vhfvigV7xg3EikRzJaB+bgU0YCFRgF5HvGPU3h8EDGQGbGMOHFXVnGSgvh+H4GJULGQHBaPMMlsL/lSTGkR15gRoVcROJmLHQlK7RhvW/kYVtgR3wgS0NJnUdGSF4mDZMlhX2kaU1mHo4cRXRkUujgdZ6kQjYgRVXkR0HCQXsGEueaT7aGUJJKReTkRdfkQYzCLN6mTaPiU/4SVlRKxlmqxXXEZb4CpFSjIEaClXx/hZ0/BivpwmAmRkVMSkoCYFhspFJtZeJXZE3N5EBl4FmuYFm25Y/wVlUChlLyoEW+5Kh2mSn7XmU+xjeC4cqQ5EI65FRBpYccpmUXRkrhHmkj5EVvEJKLJaLj5ELvpeDy5EISHEbU5EWFgminXmv0SbiChD85JEaupFAvZnuDZm5KynhEBDXGgItdJFeAWnTsCmdoZV7q2EcWHEUdgBNVlnlcximLpau1RhvlZEFuSkx5xBBxwB5f5FlD3EReKfPyVnLnWndNBnxChYpfXEUbAARTqoTzBcz9hkUd5nC6RjCK2FShqBEcQCv+fAqMhwZiCqKMi5Z8NcZdSUaAUaqPkeRYNs3RACRHTyXEPShMOGCQcMQyKiZxVug/RcKJEWqHusZwZoQnrhoY7WZCGRZjTaKNoWqAGunf6eJwrmZN9p32HqBAziYhHChFcxxEdYAR7SqEUiqOBEZ6G2XPbRaZCQYWoWG8696QCAQc1SqR8uqaAsZ0aMaAZ8V8QthS1B58XIaIPcZUY0QGQWqQFegfoQZk5Y6ijeaUfyZ8aYQSwuqcjkKYoihg8ehGakJ2f+hF1KhRBeKtPR5hR1adomqYnCqh/0ap8wl+eChEs2otAyhsd0avMuBFwUKDEuqfEygGIUYg84WTCqan/c8qNKjoS0eCnNioCRMoEW4qseeGm9hgRjEoQwHqoIHoQGXmlKmKtjwqr6EqsR+AS8yAP8jAP+YCZ+jol8aqdCdsSgqkRz8qIqlijHcCu/UqrdqAS+iAP8aAO8AAM6gAM6yAPC4sS8ikputoQghoRnCoZ0YpG87oPjTBS2BqrNsoBfIqiHKCt3IoS9KAOHhsMkQAGfQEG6hAPceoSMYuf25WwAeqO42oQyXClTwueI3UHdhAKdwAHcIC1WgsKdxAKWWsHm3AH1LoR8wAPHrsOAAAG8BAPfAGy82ATKwsRS3scqioRM7MUrykQk5C3D9GyFdGsDgGANLG28EC0WwAPWvAQBnQRCWpbsl1GmnfLWlFbEF94EZTaqScrEYKrEh3rsXBLF4wbCXQBA2u7ZCnLG+WaoC+LEHzJiAC6unbpofqAuOrguAAQD/CwCKfbsfAguWVCu6MpvEK4Xf/iCm8x65cVEQ0ImhCdexLy4LFH67HAALw38LiMqw7rUBOE2xI12Zmta5X3WhDfCxvyALJqC7xrSxdGC7zxwGI/cb44mLS5ebkEUbnjNRO8W73wsA7/m7ht27+hKxjHaamdOr6S8roHYb8SQbytqFyJGhPrQL3s+78AEAxrS73wQBUzSoQQ1LArAZ27FrObaxH0wKAwwbsAvMHxAAmL8LYWzL2ws1/0uxCxq1E+ilTlSxB36hCT1hEIbJUQzBHzMMNq27sg678eKw81IaSSsqGDu1+F2RNON8GVd4cSXMQboQ9q28IdC78zDAzGG3WUy1/Ra3p8y8AF8aYMF7NDHKz/NMG+7GsJu7C+1OvET8zFBaG/eYFykiSmXCFrOywRANzCjUsXYcC4LVzGZgzCPVEPjtxgPUwhUlyfcOzA8VbIEXG7eLwXdFHBkQuJN5wQS8p9CQvF96tmbnxrHYEGP+wQJ/wSoQsPkOC+jDzJlUaKPWGLHpGr3FmZxACM/JTJV5EP8QDAunC963CwnhPLe0OdCRuhSQHIfDwQGZlZWaEPBjsPukwUd5vDX3rNr1bJoLgT9ZVrInwad+vLYMnJJeF0rYbOElzKGJqw4bxfmSlwbCwXlwwR9fDPEJG5FzFhpxHHEzGWELRfn6s0+Fs8grwRzCuVpyHO90HOidG3oHoR4TUJzSvhx1mxtA2dG1eM0fO4E/bsFik9GsfZsBMtl/2MnAJtewBKxQp8qBgdEu7nEarcog+9D8uQkQRNxCuXKzkdEjPNpPBMEn3btK8sP/GWxqOiwgJ605vy07z6zfQq1Q+h1cuyX9sizcE8EUcd0RyBA1x9FyvNkL/cnFYdEXO3tGldhfj81j5xtxGrUc+bEGKgya5pzvuw1gOhD2DHmjy91FBROXxC1RoBa/qokFiN0BKR1xdRbCvEy5Yh2RJBzYbWmrOMiHe9GYV9h+v8F3PX0/KqXHNNjXtNaiDNEeFLnf9rDLgbI6wdIQkefYq0zW6tfRJTdZuQbXDKtc8pV9oDopKMfamIHUkxXSb5GqZQfYnHqdiknbwU4dcuEcS6J9hYAaOpWXj/pdlkBtj74Jk7Ubl1ixY7p3Benb8PaddShdXljd0O8dIT4aUYQdx34UMrx90AltR2O2fNPRD1OhGoPSoi/NpNUblN6h2199nMiNk8od9vEZudecqw0dQqktOj3ROzCRjjCZwf0du3Ad/xLXn+Xd7tfRwwmgyrTVQATmD/xdnQiqA53eDIp+B/8eIMwePeWdY4bhQkrNwLHXXtkeK1AqM6jkbkXWmHDRI1aeIipaMjTRHiLRFLbhLJWLX/M5WFeBF3D5ngxSngCBqWubZf6b3JcfGbK1e5Gw2Qy00SDuoRH5xrOoosPg4VBS6Sdz6CUv6pTa4P8yehconkRkGUoG0x8t01CXvlRvjnTF3W2BwS9G0WxFnl8dawWb4wgQzcTVGGePbUHoEJxv2dWXG295FgFYbpIdLkMiO+HrEMhj4QbL4V362h6+yton5wcT51le4QaY6Rmx4+sy4Q2s1fEm7Wa7zXpo4TWKxKvQ4TFE6VOjoJoICeTsGKJMhwuY2Di4boSjGS6enH+nvgML3b3PgRwLxyee4QjNDtQ0FxIhGGRKRxxs0SgjnUJSzkWNHsyn5gA24Q5o6nFRZwNz00Faje2NMWGWbJqzHuEFWc38VuVA9/PegOEa6IlRd/EH1Nnbd4Ekg3eMuw4hcR8iRR7L8dEif/7RQPqwzwbpdlXescFux9nNwwmQkv/zmCJekkMuvbvuw7sc40LynQiMr57W0VwTEj9/Nc8WNgWpaLXhDpJZebTklURQ+5zT5OOBGYgxJMV2k8f+sCvvEHEfERQeL4+uuCeO0REQ0851wEEYABaCLKMu238fLsOfH4nRHH/hQPqyKGjgZk7+xZFjg3N6BeQzPGg6+Ei2UHOPSB69xSQZx9LJBlshIzkglpTPdFXI0O0TD7iVK0F/WYK8J7n988nxAAuOf7gGKhLyNdQgwe4pdbj53VCRWQDomu3sYVf4rkLocssy7KIfNdQzPGX/dMqe8eVshmv9n3/hJ/PyUVxvoU/zFjT8lK4uh+obmvFTEJ7nwQrB6cIjFpai9/uQ+TAd9sGO4QAT3zr4YhX/jBdE8RBfJe5dEk1L+jhTzwMNn7ALFP4ECCBQ0eRJhQIcJlADIthBhR4kSKFfdlemhRo8J6wyahUbZRozIxkzKKREnQY8qI9MSwXGgS5kyaBpUB0FRTYD2dPRVO8rmRmEBlmUL6HLqP2NGgFEk2JYgR6r6XU622dKjzadBMSa9+hRiNmBg0kjQx3bgs00cxJ8FCFIO2KRqeTYm5fZv35rCeYvQFVYbG6iS5eRPenZTU5NKlTJU9XtpVIBqTyugZxpx5cmHNUBvihSk16CSgULd2jqjsLv/GSVVdksa4FHXEepxn38ad8GZOncskQa0KNZPg3MXngvZZj7hx5hPpZe2Zxnbo5U0/1m2eXSTpr2utIteeci/S6n2n08z0O/z6iem/kvwrvDR7mJ+Dek1+Hn00+v0RDgdLsqni8o+l3QpEMEHMiCkPqmGCayowBUV6DjyYHoNKNquUkWSZCT/0aQxoBtMPxIPGG81CmIZpkCv1TMwtGr702hBCGCOyLyh9bOzJu6vGKvFGq1xS8UMNhUwNJ+GKZEmMEa8iKUgkfVoGDfyGTGNK4yoccKrTatRSrzCkpEmmMHFD0TomUzITyjO7E8PDt9yzisE3F8oRuDoNM+pOwAwn+xKqNv20SUlC7yPwUJaOzCtRL1tUlEshCXsrsPkU1Wg4Mmu66ysr/zEtdEYv10wJDVJr+gjUipSZRBLs3gxU1TwH3HSjRk6lyU5VI9LErMyIie8qSncd6MCrhsnSqjE1q/VODvnLzFGrgiV2H0mvkqRZi5S7EqyStBUSQ9SkrbZSAEQF0ypN0M0rEzG6vRDcrxhk1zBTA5Sz3H1mtUoSXD9Eg9xFw4CXImI+evFCSeJEzceroOGRWGO/Wuay7jqTsCaIU3JXoNYu/Ehe9CJuqpF6ib02zEE163PRZPd5ctUnSYpZJNFmU+bVR/UlKE2wGAXuX6TIKngiNPhy99KLSJPEpKYtBFAounLT+SqSieX3YUZqhooRoX1i1UpwCby52GE0SUaTrv/UTkiMqiHSp9c0Tv4V0qYc5nmfiedUGqp7b9MHb4riGhYlgRditS2Re2JwcYuKRhk6w6Tz9m3UKrO8IJIeREiZdT8/+2SQJjqqnkyovS0wx/MW79xfr8a0KLJaTkiqw4nBBCPdV94nMYGARUgf1cRwMjuSLA6Q9YKyBot3qKDp+7ZlPCqNHmgJ+lQqbcfSnWHNk86E6+JcWt0p2KvdOy99IPepLe2ebLUrpuabhG6IWFsrI9Uyuivf8MofHACFlDJFuY89ayFLcK7HEtNJImB/o48AKeK8vPkMMzLKC3f8cxRiOPAjiyHKY0RYut1JYm4CkV+COmYYXSmPIMxrFPvGepIqBdVmf0f5SCPIwoiqQC824vrQCu0lwXAZqjMby4sMXUg1yjBriQUhYGaESKMnageCVUSNBTXjL8NA7GtY9JISfSK4KsIQM5/Ki2+iB0bMELEio2Oj3ozIs+vEMTP1cGBn3mVHa0kuN+I71uH4GKErGoaCT9Qiag6WGSAOciqZYIQb25OwOJpRMydkliQd2Tu7eUuTU0ofbtDYxj1usif2M+VbongbiH0SImiAYypFAj00pTKRqRPkvEyVOVkqBJJf1Ekp/zdpSUW6MiKx7GVqPuI/lnUSjKFkozGJZTphXs6ZYFylca75o7YwM5kqyc1YknnL4jDiZZ3RBxoi+c1iAfM+Z/gmMXETtdlEw4FirGLY8AmWBdpyjuE5JAvdib7WoLKN7BRINpuTx+IEZp/lYtBDoXS+QZKzOWvsDIMKNxViDKOf2iHGk1B3GyAhdF9+ZCeDDDiVG0i0IMi6531i2hzVmVSOvCkQGVM3ib94kybR8AtKdKUJiq5qLcg0jruQh1CFhqeQxuFQznrikhBq5HrwqUnTpIkSRnz0mxYNjwnDM5ancuwhJFGau0y4MA/ahoviEZBPbRoeeWrHXSMdn7uQKv8SsnXLhiNsZEKThhLT/XKrHDts7P6JoEyMoUB3ERnhVvcxiwRGcf6h7FwH0lT64DU8jb1nraJEMsTkzyQYpUqQxJItohTIngONputgFNgDTmJZeosIi/bhK5t0xbd3uZK4kNi5otjWJLzUTkk0a5C6socksGUW8SpjmzQ8pIO0Tc27lNO3ovRUEkBzLcGWWyicwmilCtpfQUN4lGHwJBq0q2wmhnGUoiBQgzeqzXgNwlkEZdZE0MpEIwJW3ZMsQx8GJh1kkJURj4AXRAbVLFhVuNcb0UM1A2kaZWbnMVgyApas3S1GzpJYvUzinPp9IUpvRAzkTqke0TiwxSyM23pbyPVOyoGuI6EppByj+JG5RDF/PxQyH2tHE1srcudk+ybuJZk5nnVyc0GkVSfPBr5V1txiz0RPLOdFOV3t8kGEHOZkfqKaZC7WkhUVJTRHiDQkxqKUw6XcNjOux/8I3TGh3AXnuYa0zgoZ85kC9meUuMulSZawn/j8TXfdWbNyvlNZCW2TN09aIXlWVT3IslRLF6Rsnd6vivUVGMqBWi2L9ieEd/UgQKL5ly02tahdiN0qayIMqAV1lstbxQc52o47koRXc42QQJfLXUA2aX73IexhK1nVrEMrivXZbItAmmfsnSuHzktt0mmZj2kQAyYOzbFt2yxaFOY2VnytKLV8xMFQCQOs74dsTq2704mOo0MrVVSIsKpDGyLruNM9EGvHkTK0nkmnLKU51TScMQeZhG8+CdPwDfxC3h5neiZxlqCkYShR9TRZYDnyYHv6Ifxe1VG6wmyLV6TYpkzbj/5q4iRWiUQfpaFL+e6Chlu1vCf4TmZdWsVx8bTlfHXhiVwURy/YfsRUqCZ0wXspOzG8dSQvAXFBbHsDMdwgDDgIg9t6tozHiE0jiGmtz02D8SKvC4VXXoh3dGoRlOuNQQHzF9SH/fLxym4LlIF7QcTAl+cKvMm6OdhRrCRvtdME6FUuClFKghGE16RiKCReGKqrd7VLHfLDWMsHf/fDymtOb0xhjQMN+BiWN95cu1Y7ZHYneeJlPlmtUWcaqKyU0rseNXz3ffBnq2bhF99Pnjd+8iPIduU3Hyox/3i2Rm47k7fprPoHuT5BkLt9JOkDWlDGjT6qxmnkRYPTyyY/QcwPRfVz+i91gUZdgsUU5MVfIPPf7EDWT5Cl7j//+j+/8yMIACBAN5oEAkTABFTABWTABnTAB4TACJTACaTACrTAC8TADNTADeTADvTADwRBAIiBnwM80qCMDzoq0viI0CvBE1xBE1TBFjRBFoTB4YDBF/wgFDxBU6nBHMRBGZzBHnRBHkRBHyRCIPzBIMxBwNtBJWxCGyzCIaRBKDxBKqTBKIzBKWxCk9jBKwQ8E2Ka6mqVNODCG7TCG0TCIzytJ9zCJCzDJfTCNTTDLhTCLKxDHXTCPIRCBKw751/zQ+04AHv7w0EkxEI0xENExERUxEVkxE1SBrDbB0hsxEnMDAuLAUhqPUrUxKDguk30xEpZAc77RERsixsYxVO8DwAQiBjANVR0xVeExViUxVmkxVq0xVvExVzUxWELCAA7)\n",
        "\n",
        "### Pros and Cons\n",
        "\n",
        "k-NN has its strengths and weaknesses:\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "- No Explicit Training: Unlike many other machine learning algorithms, k-NN doesn't require a dedicated training step. It learns from the data directly during classification or prediction.\n",
        "- No Data Loss: All information present in the training data is retained because the algorithm stores the instances explicitly.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "- High Computation Cost: Most of the computation occurs during classification, which can be computationally expensive, especially for large datasets.\n",
        "- Memory Intensive: Since k-NN considers the entire training set during classification, it demands substantial memory capacity.\n",
        "- Sensitivity to 'k': The choice of 'k' can significantly affect the algorithm's output, making it sensitive to this hyperparameter.\n",
        "\n",
        "In this Google Colab exercise, we will explore how to implement and fine-tune the k-NN algorithm, understanding its strengths and weaknesses, and gaining practical insights into its application.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this tutorial, we will investigate using k-NN classifier on the Iris-datset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b8f49b9",
      "metadata": {
        "id": "8b8f49b9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.colors as colors\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9db05c52",
      "metadata": {
        "id": "9db05c52"
      },
      "outputs": [],
      "source": [
        "iris_data = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f6a1b595",
      "metadata": {
        "id": "f6a1b595"
      },
      "outputs": [],
      "source": [
        "# Function to divide the data into training and testing\n",
        "\n",
        "import random\n",
        "random.seed(22)\n",
        "def separate_data():\n",
        "    train_A = iris_dataset[0:40]\n",
        "    test_A = iris_dataset[40:50]\n",
        "    train_B = iris_dataset[50:90]\n",
        "    test_B = iris_dataset[90:100]\n",
        "    train_C = iris_dataset[100:140]\n",
        "    test_C = iris_dataset[140:150]\n",
        "    train = np.concatenate((train_A,train_B,train_C))\n",
        "    test =  np.concatenate((test_A,test_B,test_C))\n",
        "    return train,test\n",
        "\n",
        "iris_dataset = np.column_stack((iris_data.data,iris_data.target.T)) #Join X and Y\n",
        "iris_dataset = list(iris_dataset)\n",
        "random.shuffle(iris_dataset)\n",
        "\n",
        "Filetrain, Filetest = separate_data()\n",
        "\n",
        "X_train = np.array([i[:4] for i in Filetrain])\n",
        "y_train = np.array([i[4] for i in Filetrain])\n",
        "X_test = np.array([i[:4] for i in Filetest])\n",
        "y_test = np.array([i[4] for i in Filetest])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "06b3c2e0",
      "metadata": {
        "id": "06b3c2e0"
      },
      "outputs": [],
      "source": [
        "#Calculates distance\n",
        "def euclidean_distance(p1, p2):\n",
        "    squared_difference = 0.0\n",
        "    for i in range(len(p1)):\n",
        "        squared_difference += (p1[i] - p2[i])**2\n",
        "    final_distance = squared_difference ** 0.5\n",
        "    return final_distance\n",
        "\n",
        "def manhattan_distance(p1, p2):\n",
        "    squared_difference = 0.0\n",
        "    for i in range(len(p1)):\n",
        "        squared_difference += abs(p1[i] - p2[i])\n",
        "\n",
        "    return squared_difference\n",
        "\n",
        "def minkowski_distance(p1, p2, p):\n",
        "    distance = 0.0\n",
        "    for i in range(len(p1)):\n",
        "        distance += abs(p1[i] - p2[i]) ** p\n",
        "\n",
        "    return distance ** (1/p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "acc8422c",
      "metadata": {
        "id": "acc8422c"
      },
      "outputs": [],
      "source": [
        "def fit(test_sample, training_set, training_labels, k, d_parameter):\n",
        "\n",
        "    distances = []\n",
        "\n",
        "    # Computing the distances for all data points with respect to test sample\n",
        "\n",
        "    #    neighbours, pred_label = fit(test_instance, X_train, y_train, k, \"euclidean\")\n",
        "    #         elif distance_measure == 'Manhattan':\n",
        "    #             neighbours, pred_label = fit(test_instance, X_train, y_train, k, \"Manhattan\")\n",
        "    #         elif distance_measure == 'Minkowski':\n",
        "    #             # Set your desired 'p' value for Minkowski distance\n",
        "    #             p = 3\n",
        "    #             neighbours, pred_label = fit(test_instance, X_train, y_train, k, \"Minowski\")\n",
        "\n",
        "\n",
        "    for i in range(len(training_set)):\n",
        "        if d_parameter == \"Euclidean\":\n",
        "            distance_to_point = euclidean_distance(test_sample, training_set[i])\n",
        "        elif d_parameter == \"Manhattan\":\n",
        "            distance_to_point = manhattan_distance(test_sample, training_set[i])\n",
        "        else:\n",
        "            distance_to_point = minkowski_distance(test_sample, training_set[i],3)\n",
        "\n",
        "        distances.append([distance_to_point, training_set[i], training_labels[i]])\n",
        "    # sort the distances\n",
        "    distances.sort(key = lambda x : x[0])\n",
        "\n",
        "    # Find the k nearest neighbours according to the distances\n",
        "    k_nearest_neighbours = distances[0:k]\n",
        "\n",
        "    # Getting class with majority voting\n",
        "    label_counts = {}\n",
        "    for i in range(0, k):\n",
        "        closest_label = k_nearest_neighbours[i][2]\n",
        "\n",
        "        if (closest_label in label_counts) == True:\n",
        "            label_counts[closest_label] += 1\n",
        "        else:\n",
        "            label_counts[closest_label] = 1\n",
        "\n",
        "    labelCounts = list(label_counts.values())\n",
        "    classes = list(label_counts.keys())\n",
        "    y_pred = classes[labelCounts.index(max(labelCounts))]\n",
        "\n",
        "    return (k_nearest_neighbours, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fd35f32f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd35f32f",
        "outputId": "d14d57af-dc8f-477f-d28a-e4fd38ebcf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sample predictions for k = 3 \t\n",
            "*********************************\n",
            "test sample: [5.1 3.8 1.9 0.4] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.3 2.3 4.4 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.5 3.  5.5 1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.7 2.5 5.8 1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.2 2.9 4.3 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [7.2 3.2 6.  1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.4 2.9 1.4 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.1 2.9 4.7 1.4] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [7.1 3.  5.9 2.1] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.7 3.2 1.3 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.7 3.  5.2 2.3] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.3 2.5 4.9 1.5] \t predicted label: 2.0 \t true label: 1.0 \t Misclassified\n",
            "test sample: [6.  2.2 5.  1.5] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [7.9 3.8 6.4 2. ] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [5.4 3.  4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.9 3.2 5.7 2.3] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.9 3.1 4.9 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.6 3.  4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.5 3.5 1.3 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.6 2.9 3.6 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.2 2.2 4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.2 2.7 3.9 1.4] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.4 3.4 1.7 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.6 3.  4.1 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [4.8 3.1 1.6 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [4.6 3.2 1.4 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.8 2.8 5.1 2.4] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.6 3.4 1.4 0.3] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.  2.2 4.  1. ] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.  3.2 1.2 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n"
          ]
        }
      ],
      "source": [
        "#Euclidean or Manhattan\n",
        "what_d_parameter = \"Euclidean\"\n",
        "k = 3\n",
        "print(f'Test sample predictions for k = {k} \\t')\n",
        "print('*********************************')\n",
        "for i in range(len(X_test)):\n",
        "    #Change the last value to what you want\n",
        "    neighbours, pred_label = fit(X_test[i], X_train, y_train, k, what_d_parameter )\n",
        "    if (pred_label == y_test[i]):\n",
        "        print(f'test sample: {X_test[i]} \\t',\n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Correctly classified\")\n",
        "    else:\n",
        "\n",
        "        print(f'test sample: {X_test[i]} \\t',\n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Misclassified\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7615b203",
      "metadata": {
        "id": "7615b203"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred_label, true_label):\n",
        "    TP = 0\n",
        "    for i in range(len(pred_label)):\n",
        "        if(pred_label[i] == true_label[i]):\n",
        "            TP += 1\n",
        "\n",
        "    accuracy = (TP / len(pred_label))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cfba8e83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "cfba8e83",
        "outputId": "af76f4b7-39de-4004-8b60-4ebda7cb7136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For k = 1, Accuracy 0.9333333333333333\n",
            "For k = 3, Accuracy 0.9666666666666667\n",
            "For k = 5, Accuracy 0.9666666666666667\n",
            "For k = 7, Accuracy 0.9666666666666667\n",
            "For k = 9, Accuracy 0.9666666666666667\n",
            "For k = 11, Accuracy 0.9666666666666667\n",
            "For k = 13, Accuracy 1.0\n",
            "For k = 15, Accuracy 1.0\n",
            "For k = 17, Accuracy 0.9666666666666667\n",
            "For k = 19, Accuracy 0.9666666666666667\n",
            "For k = 21, Accuracy 0.9666666666666667\n",
            "For k = 23, Accuracy 0.9666666666666667\n",
            "For k = 25, Accuracy 0.9666666666666667\n",
            "For k = 27, Accuracy 0.9666666666666667\n",
            "For k = 29, Accuracy 0.9666666666666667\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "accuracy_list = []\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "\n",
        "for k in k_list:\n",
        "    y_pred = []\n",
        "    for test_instance in X_test:\n",
        "        \n",
        "        neighbours, pred_label = fit(test_instance, X_train, y_train, k, what_d_parameter)\n",
        "        y_pred.append(pred_label)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    print(\"For k = {}, Accuracy {}\".format(k,acc))\n",
        "\n",
        "    accuracy_list.append(acc)\n",
        "plt.plot(k_list, accuracy_list)\n",
        "\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('k vs Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dd775c7b",
      "metadata": {
        "id": "dd775c7b"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# Create color maps\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
        "\n",
        "def decision_boundary(k):\n",
        "    # For better data visulaisation we considered the first two features (petal length and sepal length)\n",
        "    # in the decision boundary plot.\n",
        "    X = np.concatenate((X_train, X_test))\n",
        "    X = X[:, :2]\n",
        "    y = np.concatenate((y_train, y_test))\n",
        "\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    Z = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    y_preds = []\n",
        "\n",
        "    for item in Z:\n",
        "        neighbours, pred_label = fit(item, X, y, k,what_d_parameter)\n",
        "        y_preds.append(pred_label)\n",
        "\n",
        "     # Put the result into a color plot\n",
        "    y_preds = np.asarray(y_preds)\n",
        "    y_preds = y_preds.reshape(xx.shape)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.pcolormesh(xx, yy, y_preds, cmap=cmap_light)\n",
        "\n",
        "    # Plot also the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\"Decision boundary for k = {0}\".format(k))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0f3066cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0f3066cb",
        "outputId": "f6d61b27-671e-4a6f-c856-624c59179398",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# # This code may take several minutes to finish\n",
        "# for k in k_list:\n",
        "#     decision_boundary(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For k = 1, Euclidean, Accuracy 93.33 %\n",
            "For k = 3, Euclidean, Accuracy 96.67 %\n",
            "For k = 5, Euclidean, Accuracy 96.67 %\n",
            "For k = 7, Euclidean, Accuracy 96.67 %\n",
            "For k = 9, Euclidean, Accuracy 96.67 %\n",
            "For k = 11, Euclidean, Accuracy 96.67 %\n",
            "For k = 13, Euclidean, Accuracy 100.00 %\n",
            "For k = 15, Euclidean, Accuracy 100.00 %\n",
            "For k = 17, Euclidean, Accuracy 96.67 %\n",
            "For k = 19, Euclidean, Accuracy 96.67 %\n",
            "For k = 21, Euclidean, Accuracy 96.67 %\n",
            "For k = 23, Euclidean, Accuracy 96.67 %\n",
            "For k = 25, Euclidean, Accuracy 96.67 %\n",
            "For k = 27, Euclidean, Accuracy 96.67 %\n",
            "For k = 29, Euclidean, Accuracy 96.67 %\n",
            "For k = 1, Manhattan, Accuracy 93.33 %\n",
            "For k = 3, Manhattan, Accuracy 96.67 %\n",
            "For k = 5, Manhattan, Accuracy 96.67 %\n",
            "For k = 7, Manhattan, Accuracy 96.67 %\n",
            "For k = 9, Manhattan, Accuracy 96.67 %\n",
            "For k = 11, Manhattan, Accuracy 96.67 %\n",
            "For k = 13, Manhattan, Accuracy 96.67 %\n",
            "For k = 15, Manhattan, Accuracy 96.67 %\n",
            "For k = 17, Manhattan, Accuracy 100.00 %\n",
            "For k = 19, Manhattan, Accuracy 100.00 %\n",
            "For k = 21, Manhattan, Accuracy 100.00 %\n",
            "For k = 23, Manhattan, Accuracy 96.67 %\n",
            "For k = 25, Manhattan, Accuracy 96.67 %\n",
            "For k = 27, Manhattan, Accuracy 96.67 %\n",
            "For k = 29, Manhattan, Accuracy 93.33 %\n",
            "For k = 1, Minkowski, Accuracy 93.33 %\n",
            "For k = 3, Minkowski, Accuracy 93.33 %\n",
            "For k = 5, Minkowski, Accuracy 93.33 %\n",
            "For k = 7, Minkowski, Accuracy 96.67 %\n",
            "For k = 9, Minkowski, Accuracy 96.67 %\n",
            "For k = 11, Minkowski, Accuracy 100.00 %\n",
            "For k = 13, Minkowski, Accuracy 100.00 %\n",
            "For k = 15, Minkowski, Accuracy 100.00 %\n",
            "For k = 17, Minkowski, Accuracy 96.67 %\n",
            "For k = 19, Minkowski, Accuracy 96.67 %\n",
            "For k = 21, Minkowski, Accuracy 96.67 %\n",
            "For k = 23, Minkowski, Accuracy 96.67 %\n",
            "For k = 25, Minkowski, Accuracy 96.67 %\n",
            "For k = 27, Minkowski, Accuracy 96.67 %\n",
            "For k = 29, Minkowski, Accuracy 96.67 %\n"
          ]
        }
      ],
      "source": [
        "# Empty list to store results\n",
        "result_list = []\n",
        "p = 3\n",
        "\n",
        "for distance_measure in ['Euclidean', 'Manhattan', 'Minkowski']:\n",
        "    for k in k_list:\n",
        "        y_pred = []\n",
        "        for test_instance in X_test:\n",
        "            if distance_measure == 'Euclidean':\n",
        "                neighbours, pred_label = fit(test_instance, X_train, y_train, k, \"Euclidean\")\n",
        "            elif distance_measure == 'Manhattan':\n",
        "                neighbours, pred_label = fit(test_instance, X_train, y_train, k, \"Manhattan\")\n",
        "            elif distance_measure == 'Minkowski':\n",
        "                # Set your desired 'p' value for Minkowski distance\n",
        "                p = 3\n",
        "                neighbours, pred_label = fit(test_instance, X_train, y_train, k, \"Minkowski\")\n",
        "            \n",
        "            y_pred.append(pred_label)\n",
        "        \n",
        "        acc = accuracy(y_pred, y_test)\n",
        "        result_list.append({'Distance Measure': distance_measure, 'k Value': k, 'Accuracy': acc})\n",
        "        print(\"For k = {}, {}, Accuracy {:.2f} %\".format(k, distance_measure, acc * 100))\n",
        "\n",
        "# Create DataFrame from the list\n",
        "result_df = pd.DataFrame(result_list)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da219de2",
      "metadata": {
        "id": "da219de2"
      },
      "source": [
        "# Distance Measures\n",
        "\n",
        "When using the k-Nearest Neighbors (k-NN) algorithm, selecting an appropriate distance measure is crucial as it affects how \"closeness\" between data points is defined. Different distance measures are used depending on the nature of the data and the problem you're trying to solve. Here, we'll explore four common distance measures:\n",
        "\n",
        "## Euclidean Distance\n",
        "\n",
        "Euclidean distance is the most widely used distance measure. It calculates the straight-line distance between two points in the feature space. For two points, $\\mathbf{p} = (x_1, y_1, z_1, \\ldots)$ and $\\mathbf{q} = (x_2, y_2, z_2, \\ldots)$, Euclidean distance is calculated as:\n",
        "\n",
        "\n",
        "$ d_{\\text{Euclidean}}(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2 + \\ldots} $\n",
        "\n",
        "\n",
        "It measures the \"as-the-crow-flies\" distance and works well for continuous data.\n",
        "\n",
        "## Manhattan Distance\n",
        "\n",
        "Manhattan distance, also known as L1 distance, calculates the sum of absolute differences between the coordinates of two points. It is especially suitable for data with a grid-like structure, such as grids or city block layouts. For points A and B, it is computed as:\n",
        "\n",
        "$ d_{\\text{Manhattan}}(\\mathbf{p}, \\mathbf{q}) = |x_2 - x_1| + |y_2 - y_1| + |z_2 - z_1| + \\ldots  $\n",
        "\n",
        "## Minkowski Distance\n",
        "\n",
        "Minkowski distance is a generalized distance measure that includes Euclidean and Manhattan distances as special cases. It's controlled by a parameter 'p,' and for 'p' equal to 1, it becomes the Manhattan distance, while for 'p' equal to 2, it's the Euclidean distance. The formula is:\n",
        "\n",
        "$ d_{\\text{Minkowski}}(\\mathbf{p}, \\mathbf{q}, p) = \\left(\\sum_{i=1}^{n} |p_i - q_i|^p\\right)^{\\frac{1}{p}}  $\n",
        "\n",
        "The choice of 'p' allows you to adjust the sensitivity to different features and data distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e957e3",
      "metadata": {
        "id": "14e957e3"
      },
      "source": [
        "## Task 1 [60 marks]\n",
        "\n",
        "In the previous exercise, we utilised the Euclidean distance measure to calculate the distances between test samples and their neighbors. Now, let's explore the impact of alternative distance measures, specifically Minkowski (with a 'p' value of 3) and Manhattan distances, on our results. In your report, follow these steps:\n",
        "\n",
        "1. **Code Implementation**: Implement the necessary code to compute Minkowski and Manhattan distances.\n",
        "\n",
        "2. **Consistent 'k' Values**: Keep the same 'k' values used in the previous code to to get the accuracy results of the distance measures used.\n",
        "\n",
        "3. **Accuracy Table**: Create a table that showcases the accuracy results for each distance measure and 'k' value.\n",
        "\n",
        "4. **Discussion**: Provide a thoughtful discussion of your findings, including any differences observed in the results and their potential implications.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TKF71OTS0_Hs",
      "metadata": {
        "id": "TKF71OTS0_Hs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hx2EAD4z3BW-",
      "metadata": {
        "id": "Hx2EAD4z3BW-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wxAOCWW93W5H",
      "metadata": {
        "id": "wxAOCWW93W5H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "P3gZWkTMSNsC",
      "metadata": {
        "id": "P3gZWkTMSNsC"
      },
      "source": [
        "# Scikit-learn Implementation\n",
        "\n",
        "If you're looking to apply k-NN algorithm to your data using Python, scikit-learn provides a convenient and user-friendly way to do so. First, you'll need to import the necessary module:\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "```\n",
        "\n",
        "You can initialise the classifier with various parameters:\n",
        "> More information can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
        "\n",
        "\n",
        "> More information on distacnce measures using scikit-learn can be found [here](https://scikit-learn.org/0.24/modules/generated/sklearn.neighbors.DistanceMetric.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92bd2ab",
      "metadata": {
        "id": "f92bd2ab"
      },
      "source": [
        "## Task 2 [40 marks]\n",
        "\n",
        "In this task, your objective is to replicate the procedure outlined in the tutorial using Scikit-Learn for the k-Nearest Neighbors (k-NN) algorithm. Follow these steps and include your findings in your report:\n",
        "\n",
        "1. **Code Implementation**: Write Python code using Scikit-Learn to perform k-NN as demonstrated in the tutorial.\n",
        "\n",
        "2. **Accuracy Comparison**: Generate a table that compares the accuracy results from Task1 with the ones obtained using Scikit-Learn for different distance measures and 'k' values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "PErxbuqS1Dxq",
      "metadata": {
        "id": "PErxbuqS1Dxq"
      },
      "outputs": [],
      "source": [
        "#Importing everything that we need\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X_train = np.array([i[:4] for i in Filetrain])\n",
        "y_train = np.array([i[4] for i in Filetrain])\n",
        "X_test = np.array([i[:4] for i in Filetest])\n",
        "y_test = np.array([i[4] for i in Filetest])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Defining and training the algorithm\n",
        "\n",
        "def fit_sklearn_knn(X_train, y_train, X_test, k, distance_measure):\n",
        "    if distance_measure == 'minkowski':\n",
        "        knn = KNeighborsClassifier(n_neighbors=k, metric=distance_measure, p=3) # set p to 3 for minkowski\n",
        "    else:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k, metric=distance_measure)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Evaluating the accuracy\n",
        "\n",
        "def evaluate_accuracy(y_pred, y_test):\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scikit-Learn: For k = 1, euclidean, Accuracy 93.33 %\n",
            "Scikit-Learn: For k = 3, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 5, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 7, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 9, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 11, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 13, euclidean, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 15, euclidean, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 17, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 19, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 21, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 23, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 25, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 27, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 29, euclidean, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 1, manhattan, Accuracy 93.33 %\n",
            "Scikit-Learn: For k = 3, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 5, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 7, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 9, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 11, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 13, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 15, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 17, manhattan, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 19, manhattan, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 21, manhattan, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 23, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 25, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 27, manhattan, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 29, manhattan, Accuracy 93.33 %\n",
            "Scikit-Learn: For k = 1, minkowski, Accuracy 93.33 %\n",
            "Scikit-Learn: For k = 3, minkowski, Accuracy 93.33 %\n",
            "Scikit-Learn: For k = 5, minkowski, Accuracy 93.33 %\n",
            "Scikit-Learn: For k = 7, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 9, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 11, minkowski, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 13, minkowski, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 15, minkowski, Accuracy 100.00 %\n",
            "Scikit-Learn: For k = 17, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 19, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 21, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 23, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 25, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 27, minkowski, Accuracy 96.67 %\n",
            "Scikit-Learn: For k = 29, minkowski, Accuracy 96.67 %\n"
          ]
        }
      ],
      "source": [
        "#Comparing the accuracy\n",
        "\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "distance_measures = ['euclidean', 'manhattan', 'minkowski']\n",
        "\n",
        "result_list_sklearn = []\n",
        "\n",
        "for distance_measure in distance_measures:\n",
        "    for k in k_list:\n",
        "\n",
        "        y_pred_sklearn = fit_sklearn_knn(X_train, y_train, X_test, k, distance_measure)\n",
        "        acc_sklearn = evaluate_accuracy(y_pred_sklearn, y_test)\n",
        "        result_list_sklearn.append({'Distance Measure': distance_measure, 'k Value': k, 'Accuracy': acc_sklearn})\n",
        "        print(\"Scikit-Learn: For k = {}, {}, Accuracy {:.2f} %\".format(k, distance_measure, acc_sklearn * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Distance Measure  k Value  Accuracy\n",
            "Custom Implementation 0         Euclidean        1  0.933333\n",
            "                      1         Euclidean        3  0.966667\n",
            "                      2         Euclidean        5  0.966667\n",
            "                      3         Euclidean        7  0.966667\n",
            "                      4         Euclidean        9  0.966667\n",
            "                      5         Euclidean       11  0.966667\n",
            "                      6         Euclidean       13  1.000000\n",
            "                      7         Euclidean       15  1.000000\n",
            "                      8         Euclidean       17  0.966667\n",
            "                      9         Euclidean       19  0.966667\n",
            "                      10        Euclidean       21  0.966667\n",
            "                      11        Euclidean       23  0.966667\n",
            "                      12        Euclidean       25  0.966667\n",
            "                      13        Euclidean       27  0.966667\n",
            "                      14        Euclidean       29  0.966667\n",
            "                      15        Manhattan        1  0.933333\n",
            "                      16        Manhattan        3  0.966667\n",
            "                      17        Manhattan        5  0.966667\n",
            "                      18        Manhattan        7  0.966667\n",
            "                      19        Manhattan        9  0.966667\n",
            "                      20        Manhattan       11  0.966667\n",
            "                      21        Manhattan       13  0.966667\n",
            "                      22        Manhattan       15  0.966667\n",
            "                      23        Manhattan       17  1.000000\n",
            "                      24        Manhattan       19  1.000000\n",
            "                      25        Manhattan       21  1.000000\n",
            "                      26        Manhattan       23  0.966667\n",
            "                      27        Manhattan       25  0.966667\n",
            "                      28        Manhattan       27  0.966667\n",
            "                      29        Manhattan       29  0.933333\n",
            "                      30        Minkowski        1  0.933333\n",
            "                      31        Minkowski        3  0.933333\n",
            "                      32        Minkowski        5  0.933333\n",
            "                      33        Minkowski        7  0.966667\n",
            "                      34        Minkowski        9  0.966667\n",
            "                      35        Minkowski       11  1.000000\n",
            "                      36        Minkowski       13  1.000000\n",
            "                      37        Minkowski       15  1.000000\n",
            "                      38        Minkowski       17  0.966667\n",
            "                      39        Minkowski       19  0.966667\n",
            "                      40        Minkowski       21  0.966667\n",
            "                      41        Minkowski       23  0.966667\n",
            "                      42        Minkowski       25  0.966667\n",
            "                      43        Minkowski       27  0.966667\n",
            "                      44        Minkowski       29  0.966667\n",
            "Scikit-Learn          0         euclidean        1  0.933333\n",
            "                      1         euclidean        3  0.966667\n",
            "                      2         euclidean        5  0.966667\n",
            "                      3         euclidean        7  0.966667\n",
            "                      4         euclidean        9  0.966667\n",
            "                      5         euclidean       11  0.966667\n",
            "                      6         euclidean       13  1.000000\n",
            "                      7         euclidean       15  1.000000\n",
            "                      8         euclidean       17  0.966667\n",
            "                      9         euclidean       19  0.966667\n",
            "                      10        euclidean       21  0.966667\n",
            "                      11        euclidean       23  0.966667\n",
            "                      12        euclidean       25  0.966667\n",
            "                      13        euclidean       27  0.966667\n",
            "                      14        euclidean       29  0.966667\n",
            "                      15        manhattan        1  0.933333\n",
            "                      16        manhattan        3  0.966667\n",
            "                      17        manhattan        5  0.966667\n",
            "                      18        manhattan        7  0.966667\n",
            "                      19        manhattan        9  0.966667\n",
            "                      20        manhattan       11  0.966667\n",
            "                      21        manhattan       13  0.966667\n",
            "                      22        manhattan       15  0.966667\n",
            "                      23        manhattan       17  1.000000\n",
            "                      24        manhattan       19  1.000000\n",
            "                      25        manhattan       21  1.000000\n",
            "                      26        manhattan       23  0.966667\n",
            "                      27        manhattan       25  0.966667\n",
            "                      28        manhattan       27  0.966667\n",
            "                      29        manhattan       29  0.933333\n",
            "                      30        minkowski        1  0.933333\n",
            "                      31        minkowski        3  0.933333\n",
            "                      32        minkowski        5  0.933333\n",
            "                      33        minkowski        7  0.966667\n",
            "                      34        minkowski        9  0.966667\n",
            "                      35        minkowski       11  1.000000\n",
            "                      36        minkowski       13  1.000000\n",
            "                      37        minkowski       15  1.000000\n",
            "                      38        minkowski       17  0.966667\n",
            "                      39        minkowski       19  0.966667\n",
            "                      40        minkowski       21  0.966667\n",
            "                      41        minkowski       23  0.966667\n",
            "                      42        minkowski       25  0.966667\n",
            "                      43        minkowski       27  0.966667\n",
            "                      44        minkowski       29  0.966667\n"
          ]
        }
      ],
      "source": [
        "result_df_sklearn = pd.DataFrame(result_list_sklearn)\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "# Combine the results from both implementations for comparison\n",
        "result_df_comparison = pd.concat([result_df, result_df_sklearn], keys=['Custom Implementation', 'Scikit-Learn'])\n",
        "print(result_df_comparison)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
